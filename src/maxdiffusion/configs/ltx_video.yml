#hardware
hardware: 'tpu'
skip_jax_distributed_system: False

jax_cache_dir: ''
weights_dtype: 'bfloat16'
activations_dtype: 'bfloat16'

run_name: ''
output_dir: 'ltx-video-output'
save_config_to_gcs: False
#Checkpoints
text_encoder_model_name_or_path: "PixArt-alpha/PixArt-XL-2-1024-MS"
prompt_enhancer_image_caption_model_name_or_path: "MiaoshouAI/Florence-2-large-PromptGen-v2.0"
prompt_enhancer_llm_model_name_or_path: "unsloth/Llama-3.2-3B-Instruct"
frame_rate: 30





# Generation parameters
ckpt_path: "/mnt/disks/diffusionproj"
prompt: "A man in a dimly lit room talks on a vintage telephone, hangs up, and looks down with a sad expression. He holds the black rotary phone to his right ear with his right hand, his left hand holding a rocks glass with amber liquid. He wears a brown suit jacket over a white shirt, and a gold ring on his left ring finger. His short hair is neatly combed, and he has light skin with visible wrinkles around his eyes. The camera remains stationary, focused on his face and upper body. The room is dark, lit only by a warm light source off-screen to the left, casting shadows on the wall behind him. The scene appears to be from a movie."
#negative_prompt: "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"
height: 512
width: 512
num_frames: 88
guidance_scale: 5.0
flow_shift: 3.0
prompt_enhancement_words_threshold: 120

#Parallelism
mesh_axes: ['data', 'fsdp', 'tensor', 'fsdp_transpose', 'expert', 'tensor_transpose', 'tensor_sequence', 'sequence']
logical_axis_rules: [
                      ['batch', 'data'],
                      ['activation_batch', ['data','fsdp']],
                      ['activation_heads', 'tensor'],
                      ['activation_kv', 'tensor'],
                      ['mlp','tensor'],
                      ['embed','fsdp'],
                      ['heads', 'tensor'],
                      ['conv_batch', ['data','fsdp']],
                      ['out_channels', 'tensor'],
                      ['conv_out', 'fsdp'],
                    ]
data_sharding: [['data', 'fsdp', 'tensor', 'fsdp_transpose', 'expert', 'tensor_transpose', 'tensor_sequence', 'sequence']]
dcn_data_parallelism: 1  # recommended DCN axis to be auto-sharded
dcn_fsdp_parallelism: -1
dcn_tensor_parallelism: 1

ici_data_parallelism: -1
ici_fsdp_parallelism: 1  # recommended ICI axis to be auto-sharded
ici_tensor_parallelism: 1
ici_fsdp_transpose_parallelism: 1
ici_sequence_parallelism: 1
ici_tensor_transpose_parallelism: 1
ici_expert_parallelism: 1
ici_sequence_parallelism: 1




learning_rate_schedule_steps: -1
max_train_steps: 500 
pretrained_model_name_or_path: ''
unet_checkpoint: ''
dataset_name: 'diffusers/pokemon-gpt4-captions'
train_split: 'train'
dataset_type: 'tf'
cache_latents_text_encoder_outputs: True
per_device_batch_size: 1
compile_topology_num_slices: -1 
quantization_local_shard_count: -1
jit_initializers: True 
enable_single_replica_ckpt_restoring: False